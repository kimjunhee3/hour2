from flask import Flask, request, render_template, jsonify, make_response
import os, json, time, re, io, zipfile
from datetime import datetime, timedelta
import pandas as pd

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

app = Flask(__name__)

# ====== ê¸°ì¤€ê°’ / ì„¤ì • ======
top30   = 168
avg_ref = 182.7
bottom70= 194
START_DATE = os.environ.get("START_DATE", "2025-03-22")

# ====== ê²½ë¡œ ======
BASE_DIR   = os.path.dirname(os.path.abspath(__file__))
DATA_DIR   = os.environ.get("DATA_DIR", os.path.join(BASE_DIR, "data", "seed"))
CACHE_DIR  = os.environ.get("CACHE_DIR", os.path.join(BASE_DIR, "data", "runtime"))

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(CACHE_DIR, exist_ok=True)

# ëŸ°íƒ€ì„ ìºì‹œ íŒŒì¼ë“¤
RUNTIME_CACHE_FILE   = os.path.join(CACHE_DIR, "runtime_cache.json")
SCHEDULE_CACHE_FILE  = os.path.join(CACHE_DIR, "schedule_index.json")
AVG_CACHE_FILE       = os.path.join(CACHE_DIR, "avg_cache.json")

# ì”¨ë“œ(ì´ë¯¸ì§€ì— í¬í•¨) ê¸°ë³¸ íŒŒì¼ëª…
SEED_RUNTIME_FILE    = os.path.join(DATA_DIR, "runtime_cache.seed.json")
SEED_SCHEDULE_FILE   = os.path.join(DATA_DIR, "schedule_index.seed.json")
SEED_AVG_FILE        = os.path.join(DATA_DIR, "avg_cache.seed.json")

# ğŸ‘‰ ì—…ë¡œë“œ JSON(plain ì´ë¦„)ë„ ìë™ íƒìƒ‰: data/seed/ ì™€ ë ˆí¬ ë£¨íŠ¸ ëª¨ë‘
SEED_PLAIN_RUNTIME_CANDIDATES  = [os.path.join(DATA_DIR, "runtime_cache.json"),
                                  os.path.join(BASE_DIR, "runtime_cache.json")]
SEED_PLAIN_SCHEDULE_CANDIDATES = [os.path.join(DATA_DIR, "schedule_index.json"),
                                  os.path.join(BASE_DIR, "schedule_index.json")]
SEED_PLAIN_AVG_CANDIDATES      = [os.path.join(DATA_DIR, "avg_cache.json"),
                                  os.path.join(BASE_DIR, "avg_cache.json")]

# ====== JSON ìœ í‹¸ ======
def _safe_json_load(path, default):
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return default
    return default

def _safe_json_save(path, obj):
    tmp = path + ".tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)
    os.replace(tmp, path)

def _merge_from_paths(paths):
    merged = {}
    for p in paths:
        obj = _safe_json_load(p, {})
        if isinstance(obj, dict) and obj:
            merged.update(obj)
    return merged

def _file_info(path):
    if not os.path.exists(path):
        return {"exists": False}
    st = os.stat(path)
    return {
        "exists": True,
        "size_bytes": st.st_size,
        "mtime": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(st.st_mtime)),
        "path": os.path.abspath(path),
    }

# ====== ì”¨ë“œ â†’ ëŸ°íƒ€ì„ ìºì‹œ ì´ˆê¸°í™” ======
def _warm_cache_from_seed_if_empty():
    # runtime_cache.json
    if not os.path.exists(RUNTIME_CACHE_FILE):
        merged = {}
        seed = _safe_json_load(SEED_RUNTIME_FILE, {})
        if isinstance(seed, dict): merged.update(seed)
        merged.update(_merge_from_paths(SEED_PLAIN_RUNTIME_CANDIDATES))
        if merged: _safe_json_save(RUNTIME_CACHE_FILE, merged)

    # schedule_index.json
    if not os.path.exists(SCHEDULE_CACHE_FILE):
        merged = {}
        seed = _safe_json_load(SEED_SCHEDULE_FILE, {})
        if isinstance(seed, dict): merged.update(seed)
        merged.update(_merge_from_paths(SEED_PLAIN_SCHEDULE_CANDIDATES))
        if merged: _safe_json_save(SCHEDULE_CACHE_FILE, merged)

    # avg_cache.json
    if not os.path.exists(AVG_CACHE_FILE):
        merged = {}
        seed = _safe_json_load(SEED_AVG_FILE, {})
        if isinstance(seed, dict): merged.update(seed)
        merged.update(_merge_from_paths(SEED_PLAIN_AVG_CANDIDATES))
        if merged: _safe_json_save(AVG_CACHE_FILE, merged)

_warm_cache_from_seed_if_empty()

# ====== ìºì‹œ Accessor ======
def get_runtime_cache():
    return _safe_json_load(RUNTIME_CACHE_FILE, {})

def get_schedule_cache():
    return _safe_json_load(SCHEDULE_CACHE_FILE, {})

def get_avg_cache():
    return _safe_json_load(AVG_CACHE_FILE, {})

def set_runtime_cache(key, runtime_min):
    cache = get_runtime_cache()
    cache[key] = {"runtime_min": runtime_min}
    _safe_json_save(RUNTIME_CACHE_FILE, cache)

def set_schedule_cache_for_date(date_str, games_minimal_list):
    cache = get_schedule_cache()
    cache[date_str] = games_minimal_list
    _safe_json_save(SCHEDULE_CACHE_FILE, cache)

def set_avg_cache(key, payload):
    cache = get_avg_cache()
    cache[key] = payload
    _safe_json_save(AVG_CACHE_FILE, cache)

def make_runtime_key(game_id: str, game_date: str) -> str:
    return f"{game_id}_{game_date}"

def make_avg_key(team: str, rivals_set, start_date: str) -> str:
    sig = "ALL" if not rivals_set else ",".join(sorted(rivals_set))
    sd = start_date.replace("-", "")
    return f"{team}|{sig}|{sd}"

# ====== Selenium ======
def make_driver():
    options = Options()
    options.binary_location = os.environ.get("CHROME_BIN", "/usr/bin/google-chrome")
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1280,1200")
    options.add_argument("--lang=ko-KR")
    options.add_argument("--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0 Safari/537.36")
    options.page_load_strategy = "eager"
    return webdriver.Chrome(options=options)

# ====== ì˜¤ëŠ˜ ì¹´ë“œ ======
def get_today_cards(driver):
    wait = WebDriverWait(driver, 15)
    today = datetime.today().strftime("%Y%m%d")
    url = f"https://www.koreabaseball.com/Schedule/GameCenter/Main.aspx?gameDate={today}"
    driver.get(url)
    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div#contents")))
    time.sleep(0.4)
    soup = BeautifulSoup(driver.page_source, "html.parser")
    return soup.select("li.game-cont") or soup.select("li[class*='game-cont']")

def extract_match_info_from_card(card_li):
    home_nm = card_li.get("home_nm")
    away_nm = card_li.get("away_nm")
    g_id = card_li.get("g_id")
    g_dt = card_li.get("g_dt")

    if not (home_nm and away_nm):
        home_alt = card_li.select_one(".team.home .emb img")
        away_alt = card_li.select_one(".team.away .emb img")
        if away_alt and not away_nm: away_nm = (away_alt.get("alt") or "").strip() or None
        if home_alt and not home_nm: home_nm = (home_alt.get("alt") or "").strip() or None

    if not (home_nm and away_nm):
        txt = card_li.get_text(" ", strip=True)
        m = re.search(r"([A-Za-zê°€-í£]+)\s*vs\s*([A-Za-zê°€-í£]+)", txt, re.I)
        if m:
            a, b = m.group(1), m.group(2)
            away_nm = away_nm or a
            home_nm = home_nm or b

    if not (g_id and g_dt):
        a = card_li.select_one("a[href*='GameCenter/Main.aspx'][href*='gameId='][href*='gameDate=']")
        if a and a.has_attr("href"):
            href = a["href"]
            gm = re.search(r"gameId=([A-Z0-9]+)", href)
            dm = re.search(r"gameDate=(\d{8})", href)
            if gm: g_id = g_id or gm.group(1)
            if dm: g_dt = g_dt or dm.group(1)

    return {"home": home_nm, "away": away_nm, "g_id": g_id, "g_dt": g_dt}

def find_today_matches_for_team(driver, my_team):
    cards = get_today_cards(driver)
    results = []
    for li in cards:
        info = extract_match_info_from_card(li)
        h, a = info["home"], info["away"]
        if not (h and a): continue
        if my_team in {h, a}:
            rival = h if a == my_team else a
            info["rival"] = rival
            results.append(info)
    return results

# ====== ë‚ ì§œ ìŠ¤ì¼€ì¤„(ìµœì†Œí•„ë“œ ìºì‹œ) ======
def get_games_for_date(driver, date_str):
    cache = get_schedule_cache()
    if date_str in cache:
        return cache[date_str]

    wait = WebDriverWait(driver, 15)
    url = f"https://www.koreabaseball.com/Schedule/GameCenter/Main.aspx?gameDate={date_str}"
    driver.get(url)
    try:
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div#contents")))
    except Exception:
        set_schedule_cache_for_date(date_str, [])
        return []

    time.sleep(0.3)
    soup = BeautifulSoup(driver.page_source, "html.parser")
    cards = soup.select("li.game-cont") or soup.select("li[class*='game-cont']")

    out = []
    for li in cards:
        info = extract_match_info_from_card(li)
        if all([info.get("home"), info.get("away"), info.get("g_id"), info.get("g_dt")]):
            out.append({"home": info["home"], "away": info["away"], "g_id": info["g_id"], "g_dt": info["g_dt"]})

    set_schedule_cache_for_date(date_str, out)
    return out

# ====== ë¦¬ë·° ëŸ¬ë‹íƒ€ì„ ======
def open_review_and_get_runtime(driver, game_id, game_date):
    today_str = datetime.today().strftime("%Y%m%d")
    use_cache = (game_date != today_str)
    key = make_runtime_key(game_id, game_date)

    if use_cache:
        rc = get_runtime_cache()
        hit = rc.get(key)
        if hit and isinstance(hit, dict) and "runtime_min" in hit:
            return hit["runtime_min"]

    wait = WebDriverWait(driver, 12)
    base = f"https://www.koreabaseball.com/Schedule/GameCenter/Main.aspx?gameId={game_id}&gameDate={game_date}"
    driver.get(base)
    try:
        tab = wait.until(EC.element_to_be_clickable((By.XPATH, "//a[contains(text(), 'ë¦¬ë·°')]")))
        tab.click()
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.record-etc")))
    except Exception:
        driver.get(base + "&section=REVIEW")
        try:
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.record-etc")))
        except Exception:
            pass

    time.sleep(0.3)
    soup = BeautifulSoup(driver.page_source, "html.parser")
    run_time_min = None
    box = soup.select_one("div.record-etc")
    if box:
        span = box.select_one("span#txtRunTime")
        if span:
            txt = span.get_text(strip=True)
            m = re.search(r"(\d{1,2})\s*[:ï¼š]\s*(\d{2})", txt)
            if m:
                h, mn = int(m.group(1)), int(m.group(2))
                run_time_min = h * 60 + mn

    if use_cache and run_time_min is not None:
        set_runtime_cache(key, run_time_min)
    return run_time_min

# ====== ìŠ¤ì¼€ì¤„ ì»¤ë²„ë¦¬ì§€ ë³´ì¥(í•„ìš”í•  ë•Œë§Œ Selenium í˜¸ì¶œ) ======
def _date_range_list(start_date: str, end_date: str):
    if "-" in start_date:
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
    else:
        start_dt = datetime.strptime(start_date, "%Y%m%d")
    end_dt = datetime.strptime(end_date, "%Y%m%d")
    return [dt.strftime("%Y%m%d") for dt in pd.date_range(start=start_dt, end=end_dt)]

def _gather_games_from_schedule_cache(team_name, rivals_set, dates):
    sch = get_schedule_cache()
    targets = []
    for d in dates:
        games = sch.get(d)
        if not games:
            continue
        for g in games:
            h, a = g["home"], g["away"]
            if team_name not in {h, a}:
                continue
            opp = h if a == team_name else a
            if rivals_set and opp not in rivals_set:
                continue
            targets.append(g)
    return targets

def _collect_runtime_from_runtime_cache(games):
    rc = get_runtime_cache()
    have, missing = [], []
    today_str = datetime.today().strftime("%Y%m%d")
    for g in games:
        k = make_runtime_key(g["g_id"], g["g_dt"])
        hit = rc.get(k)
        if g["g_dt"] == today_str:
            missing.append(g)  # ì˜¤ëŠ˜ ê²½ê¸°ëŠ” ë¦¬ë·° ë¯¸ê²Œì‹œ ê°€ëŠ¥ì„±
        elif hit and "runtime_min" in hit:
            have.append(hit["runtime_min"])
        else:
            missing.append(g)
    return have, missing

def _ensure_schedule_coverage(dates, driver=None):
    created = False
    sch = get_schedule_cache()
    missing = [d for d in dates if d not in sch]
    if not missing:
        return
    if driver is None:
        driver = make_driver()
        created = True
    for dt in missing:
        try:
            get_games_for_date(driver, dt)
        except Exception:
            # ë‚ ì§œ í•˜ë‚˜ ì‹¤íŒ¨í•´ë„ ê³„ì†
            continue
    if created:
        try: driver.quit()
        except: pass

# ====== í‰ê·  ê³„ì‚°: ìºì‹œ ìš°ì„  + ë¶€ì¡±ë¶„ Selenium ë³´ì¶© ======
def collect_history_avg_runtime(team_name, rival_set, start_date=START_DATE):
    yesterday = (datetime.today() - timedelta(days=1)).strftime("%Y%m%d")
    dates = _date_range_list(start_date, yesterday)

    # 1) ìŠ¤ì¼€ì¤„ ìºì‹œë§Œìœ¼ë¡œ ì‹œë„
    targets = _gather_games_from_schedule_cache(team_name, rival_set, dates)

    # 2) ë¹„ì–´ìˆìœ¼ë©´ í•„ìš”í•œ ë‚ ì§œë§Œ Seleniumìœ¼ë¡œ ì±„ì›€
    if not targets:
        _ensure_schedule_coverage(dates)  # ë‚´ë¶€ì—ì„œ í•„ìš” ì‹œ ë“œë¼ì´ë²„ ìƒì„±/í•´ì œ
        targets = _gather_games_from_schedule_cache(team_name, rival_set, dates)

    # 3) ëŸ¬ë‹íƒ€ì„ ìºì‹œ ë¨¼ì €
    have, missing = _collect_runtime_from_runtime_cache(targets)

    # 4) ì—†ëŠ” ê²½ê¸°ë§Œ ë¦¬ë·° íƒ­ ì ‘ê·¼
    if missing:
        d = make_driver()
        try:
            # í˜¹ì‹œ ìŠ¤ì¼€ì¤„ì´ ë” í•„ìš”í•œ ë‚ ì§œê°€ ìˆë‹¤ë©´ ë³´ê°•
            need_dates = sorted({g["g_dt"] for g in missing if g.get("g_dt")})
            for dt in need_dates:
                if dt not in get_schedule_cache():
                    get_games_for_date(d, dt)

            # ë‹¤ì‹œ ëŒ€ìƒ/ë¯¸ì‹± ê³„ì‚°
            targets = _gather_games_from_schedule_cache(team_name, rival_set, dates)
            have, missing = _collect_runtime_from_runtime_cache(targets)

            for g in missing:
                try:
                    rt = open_review_and_get_runtime(d, g["g_id"], g["g_dt"])
                except Exception:
                    rt = None
                if rt is not None:
                    have.append(rt)
        finally:
            try: d.quit()
            except: pass

    if have:
        return round(sum(have) / len(have), 1), have
    return None, []

# ====== ê³µí†µ ì²˜ë¦¬ ======
def compute_for_team(team_name):
    if not team_name:
        return dict(result="íŒ€ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", avg_time=None, css_class="", msg="",
                    selected_team=None, top30=top30, avg_ref=avg_ref, bottom70=bottom70)

    # ì˜¤ëŠ˜ ë§¤ì¹˜ì—…: ì´ ë‹¨ê³„ëŠ” ë“œë¼ì´ë²„ í•„ìš”
    d = make_driver()
    try:
        today_matches = find_today_matches_for_team(d, team_name)
    finally:
        try: d.quit()
        except: pass

    if not today_matches:
        return dict(result=f"{team_name}ì˜ ì˜¤ëŠ˜ ê²½ê¸°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                    avg_time=None, css_class="", msg="",
                    selected_team=team_name, top30=top30, avg_ref=avg_ref, bottom70=bottom70)

    rivals_today = {m["rival"] for m in today_matches if m.get("rival")}
    rivals_str = ", ".join(sorted(rivals_today)) if rivals_today else ""

    # ì§‘ê³„ ìºì‹œ ë¨¼ì €
    avg_key = make_avg_key(team_name, rivals_today, START_DATE)
    avg_cache = get_avg_cache()
    if avg_key in avg_cache and "avg_time" in avg_cache[avg_key] and avg_cache[avg_key]["avg_time"] is not None:
        avg_time = avg_cache[avg_key]["avg_time"]
    else:
        try:
            avg_time, samples = collect_history_avg_runtime(team_name, rivals_today)
        except Exception:
            avg_time, samples = None, []
        # ì‹¤íŒ¨(None)ëŠ” ìºì‹œì— ì €ì¥í•˜ì§€ ì•ŠìŒ (ì˜¤ì—¼ ë°©ì§€)
        if avg_time is not None and samples:
            set_avg_cache(avg_key, {
                "avg_time": avg_time,
                "n_samples": len(samples),
                "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })

    css_class = ""; msg = ""
    if avg_time is not None:
        if avg_time < top30:        css_class, msg = "fast", "ë¹ ë¥´ê²Œ ëë‚˜ëŠ” ê²½ê¸°ì…ë‹ˆë‹¤"
        elif avg_time < avg_ref:    css_class, msg = "normal", "ì¼ë°˜ì ì¸ ê²½ê¸° ì†Œìš” ì‹œê°„ì…ë‹ˆë‹¤"
        elif avg_time < bottom70:   css_class, msg = "bit-long", "ì¡°ê¸ˆ ê¸´ í¸ì´ì—ìš”"
        else:                       css_class, msg = "long", "ì‹œê°„ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ë§¤ì¹˜ì—…ì…ë‹ˆë‹¤"
        result = f"ì˜¤ëŠ˜ {team_name}ì˜ ìƒëŒ€íŒ€ì€ {rivals_str}ì…ë‹ˆë‹¤.<br>ê³¼ê±° {team_name} vs {rivals_str} í‰ê·  ê²½ê¸°ì‹œê°„: {avg_time}ë¶„"
    else:
        result = f"ì˜¤ëŠ˜ {team_name}ì˜ ìƒëŒ€íŒ€ì€ {rivals_str}ì…ë‹ˆë‹¤.<br>ê³¼ê±° ê²½ê¸° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    return dict(result=result, avg_time=avg_time, css_class=css_class, msg=msg,
                selected_team=team_name, top30=top30, avg_ref=avg_ref, bottom70=bottom70)

# ====== ë¼ìš°íŠ¸ ======
@app.route("/", methods=["GET","POST"])
@app.route("/hour", methods=["GET","POST"])
def hour_index():
    try:
        team = (request.args.get("myteam") or request.form.get("myteam") or "").strip()
        ctx = compute_for_team(team) if team else dict(
            result=None, avg_time=None, css_class="", msg="",
            selected_team=None, top30=top30, avg_ref=avg_ref, bottom70=bottom70
        )
        return render_template("hour.html", **ctx)
    except Exception as e:
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {type(e).__name__}: {str(e)}", 200

# ====== í—¬ìŠ¤/ìºì‹œ ìœ í‹¸ ======
@app.route("/healthz")
def healthz():
    return "ok", 200

@app.route("/cache/status")
def cache_status():
    return jsonify({
        "BASE_DIR": os.path.abspath(BASE_DIR),
        "DATA_DIR": os.path.abspath(DATA_DIR),
        "CACHE_DIR": os.path.abspath(CACHE_DIR),
        "runtime_cache": _file_info(RUNTIME_CACHE_FILE),
        "schedule_cache": _file_info(SCHEDULE_CACHE_FILE),
        "avg_cache": _file_info(AVG_CACHE_FILE),
        "seed_runtime": _file_info(SEED_RUNTIME_FILE),
        "seed_schedule": _file_info(SEED_SCHEDULE_FILE),
        "seed_avg": _file_info(SEED_AVG_FILE),
        "seed_plain_candidates": {
            "runtime": [ _file_info(p) for p in SEED_PLAIN_RUNTIME_CANDIDATES ],
            "schedule": [ _file_info(p) for p in SEED_PLAIN_SCHEDULE_CANDIDATES ],
            "avg": [ _file_info(p) for p in SEED_PLAIN_AVG_CANDIDATES ],
        }
    })

@app.route("/cache/clear", methods=["POST"])
def cache_clear():
    deleted = []
    for p in [RUNTIME_CACHE_FILE, SCHEDULE_CACHE_FILE, AVG_CACHE_FILE]:
        if os.path.exists(p):
            try:
                os.remove(p); deleted.append(os.path.basename(p))
            except Exception as e:
                return jsonify({"ok": False, "error": str(e)}), 500
    _warm_cache_from_seed_if_empty()
    return jsonify({"ok": True, "deleted": deleted})

# ====== ì”¨ë“œ Export/Import ======
@app.route("/cache/export")
def cache_export():
    runtime = _safe_json_load(RUNTIME_CACHE_FILE, {})
    schedule= _safe_json_load(SCHEDULE_CACHE_FILE, {})
    avg     = _safe_json_load(AVG_CACHE_FILE, {})
    mem = io.BytesIO()
    with zipfile.ZipFile(mem, "w", zipfile.ZIP_DEFLATED) as z:
        z.writestr("runtime_cache.seed.json", json.dumps(runtime, ensure_ascii=False, indent=2))
        z.writestr("schedule_index.seed.json", json.dumps(schedule, ensure_ascii=False, indent=2))
        z.writestr("avg_cache.seed.json", json.dumps(avg, ensure_ascii=False, indent=2))
    mem.seek(0)
    resp = make_response(mem.read())
    resp.headers["Content-Type"] = "application/zip"
    resp.headers["Content-Disposition"] = "attachment; filename=hour_cache_seed.zip"
    return resp

@app.route("/cache/import", methods=["POST"])
def cache_import():
    """
    JSON body:
    {
      "runtime": { ... },     # optional
      "schedule": { ... },    # optional
      "avg": { ... }          # optional
    }
    """
    try:
        payload = request.get_json(force=True, silent=False)
    except Exception:
        return jsonify({"ok": False, "error": "invalid json"}), 400

    applied = {}
    if isinstance(payload, dict) and "runtime" in payload:
        _safe_json_save(RUNTIME_CACHE_FILE, payload["runtime"])
        _safe_json_save(SEED_RUNTIME_FILE, payload["runtime"])
        applied["runtime"] = True
    if isinstance(payload, dict) and "schedule" in payload:
        _safe_json_save(SCHEDULE_CACHE_FILE, payload["schedule"])
        _safe_json_save(SEED_SCHEDULE_FILE, payload["schedule"])
        applied["schedule"] = True
    if isinstance(payload, dict) and "avg" in payload:
        _safe_json_save(AVG_CACHE_FILE, payload["avg"])
        _safe_json_save(SEED_AVG_FILE, payload["avg"])
        applied["avg"] = True

    if not applied:
        return jsonify({"ok": False, "error": "no 'runtime' or 'schedule' or 'avg' in body"}), 400

    return jsonify({"ok": True, "applied": applied})

if __name__ == "__main__":
    app.run(debug=True, port=5002, use_reloader=False)
